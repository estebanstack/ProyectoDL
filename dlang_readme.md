# ðŸ“˜ DLang â€“ Mini lenguaje para CÃ¡lculo NumÃ©rico, GrÃ¡ficas y Redes Neuronales

## 1. DescripciÃ³n general

Este proyecto implementa un **lenguaje de dominio especÃ­fico (DSL)** llamado **DLang**, diseÃ±ado para permitir al usuario realizar tareas tÃ­picas de cÃ¡lculo numÃ©rico, Ã¡lgebra de matrices, aprendizaje automÃ¡tico y visualizaciÃ³n, *todo sin usar librerÃ­as externas* como `math`, `numpy` o `matplotlib`.

DLang funciona gracias a:

* Una **gramÃ¡tica ANTLR4**.
* Un **intÃ©rprete propio** en Python (Visitor).
* Bibliotecas internas implementadas totalmente a mano.

El resultado es un mini-lenguaje completo con:

* AritmÃ©tica, trigonometrÃ­a, raÃ­ces.
* Matrices: suma, resta, multiplicaciÃ³n, transpuesta, inversa.
* Archivos simulados (sin `open()` real).
* GrÃ¡ficas ASCII estilo matplotlib.
* RegresiÃ³n lineal.
* PerceptrÃ³n multicapa (MLP) desde cero.
* Red competitiva para clustering.

---

## 2. Requisitos

* Python **3.10+**
* ANTLR4 instalado globalmente:

  ```bash
  pip install antlr4-python3-runtime
  ```
* Ejecutable de ANTLR (`antlr4` o `antlr4.bat` en Windows)

---

## 3. CompilaciÃ³n de la gramÃ¡tica

El archivo central del lenguaje es:

```
DLang.g4
```

Para generar el parser y visitor:

```bash
antlr4 -Dlanguage=Python3 -visitor DLang.g4
```

---

## 4. EjecuciÃ³n del intÃ©rprete

### Ejecutar un programa `.dl`:

```bash
python Main.py archivo.dl
```

### Modo interactivo (REPL):

```bash
python Main.py
```

---

## 5. Estructura del proyecto

### 5.1 NÃºcleo del lenguaje

| Archivo            | DescripciÃ³n                                             |
| ------------------ | ------------------------------------------------------- |
| **DLang.g4**       | GramÃ¡tica completa del lenguaje DLang escrita en ANTLR4 |
| **Main.py**        | Punto de entrada, ejecuta archivos o abre REPL          |
| **EvalVisitor.py** | IntÃ©rprete: ejecuta sentencias y expresiones del DSL    |

EvalVisitor:

* Maneja variables, funciones, control de flujo.
* Llama funciones internas segÃºn nombre (`sin`, `plot`, `mat_mul`, etc.)
* Diferencia entre valores escalares, listas y matrices.

---

## 5.2 Bibliotecas internas implementadas a mano

### ðŸ”¢ MyMath.py

* ImplementaciÃ³n manual de:

  * `sin(x)`, `cos(x)` â†’ series de Taylor.
  * `tan(x)`
  * `sqrt(x)` â†’ Newton-Raphson.
  * `exp`, `factorial`, `potencia`.

Sin usar `math`.

---

### ðŸ“ Matrix.py

Soporte completo para matrices:

* `mat_add(A, B)`
* `mat_sub(A, B)`
* `mat_mul(A, B)` (triple for)
* `mat_transpose(A)`
* `mat_inverse(A)` usando Gauss-Jordan

En el lenguaje, las listas dobles `[ [..], [..] ]` se interpretan como matrices automÃ¡ticamente.

---

### ðŸ“ MyFile.py â€” Filesystem simulado

Sin usar `open()`.
Usa un diccionario interno:

```python
FS["ruta.txt"] = "contenido"
```

Funciones:

* `write_text`
* `append_text`
* `read_text`
* `read_lines`

---

### ðŸ“Š MyPlot.py â€“ Motor de grÃ¡ficos ASCII estilo matplotlib

Este mÃ³dulo replica una API similar a `matplotlib.pyplot`, pero todo se imprime en ASCII:

Funciones disponibles:

* `figure(width, height)`
* `plot(xs, ys)`
* `scatter(xs, ys)`
* `title(text)`
* `xlabel(text)`
* `ylabel(text)`
* `show()`
* `clf()`
* `close()`

CaracterÃ­sticas:

* Renderizado en una rejilla de caracteres.
* Ejes X/Y automÃ¡ticos.
* MÃºltiples series con distintos marcadores.
* Algoritmo de Bresenham para unir puntos.

---

### ðŸ“ˆ MyRegression.py

Implementa regresiÃ³n lineal:

* `regresion_lineal(xs, ys)` â†’ retorna `m, b`
* `predecir_lineal(xs, (m,b))` â†’ calcula ys pronosticados

Sin librerÃ­as, usando las fÃ³rmulas de mÃ­nimos cuadrados.

---

### ðŸ§  MyMLP.py â€” PerceptrÃ³n Multicapa

Red neuronal hecha 100% a mano:

* FunciÃ³n de activaciÃ³n: sigmoide implementada con Taylor.
* Backpropagation manual.
* InicializaciÃ³n determinista (no se usa random).
* MÃ©todos:

  * `train(X, Y, lr, epochs)`
  * `predict(X)`
  * `predict_real_mlp()`

Se usa para aprender el problema XOR.

---

### ðŸŒ MyClusterNN.py â€“ Red competitiva

Una red tipo "k-means neural":

* Centros iniciales deterministas.
* Entrenamiento por regla del ganador (winner-takes-all).
* `train_cluster_net(model, X, lr, epochs)`
* `predict_cluster(model, X)`

---

## 6. Sintaxis del DSL

### Variables:

```dl
x = 5
msg = "hola"
lista = [1, 2, 3]
```

### Condicionales:

```dl
if x > 3 {
    print("mayor")
}
```

### Funciones definidas por el usuario:

```dl
def doble(n) {
    return n * 2
}
print(doble(5))
```

### While:

```dl
i = 0
while i < 5 {
    print(i)
    i = i + 1
}
```

---

## 7. Ejemplos completos

### RegresiÃ³n + grÃ¡fica ASCII

```dl
xs = [1,2,3,4,5]
ys = [2,3,5,4,5]

params = regresion_lineal(xs, ys)
ys_pred = predecir_lineal(xs, params)

figure(60,20)
plot(xs, ys, label="Datos")
plot(xs, ys_pred, label="PredicciÃ³n")
title("RegresiÃ³n Lineal")
xlabel("x")
ylabel("y")
show()
```

### MLP XOR

```dl
X = [[0,0],[0,1],[1,0],[1,1]]
Y = [0,1,1,0]

m = create_mlp(2,4,1)
train_mlp(m, X, Y, 0.5, 8000)
print(predict_mlp(m, X))
```

---

## 8. Decisiones de diseÃ±o

* No usar ninguna librerÃ­a externa **por requerimiento del proyecto**.
* Implementar todo desde cero:

  * TrigonometrÃ­a
  * Algebra lineal
  * Plotting
  * Redes neuronales
* Hacer un lenguaje extensible y fÃ¡cil de leer gracias a ANTLR.
* Emular las funciones de `matplotlib.pyplot` para facilidad del usuario.

---

## 9. Trabajo futuro

* AÃ±adir funciones logarÃ­tmicas y exponenciales con mayor precisiÃ³n.
* MLP multiclase y mÃ¡s capas.
* Mejor visualizaciÃ³n ASCII.
* ExportaciÃ³n/importaciÃ³n de modelos entrenados.

---

## 10. Autores

Proyecto desarrollado como parte del curso de Compiladores.

---

## 11. Licencia

Este proyecto es de cÃ³digo abierto y estÃ¡ disponible bajo la licencia MIT.